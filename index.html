
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Zhongqi Yue; Nanyang Technological University; Singapore; Causal Inference; Disentangled Representation; NTU; Transfer Learning; Generalization; ICCV; ECCV; CVPR; Few-shot Learning; Domain Adaptation; Computer Vision; Machine Learning">
    <link rel="author" href="https://yue-zhongqi.github.io/">
    <title>Zhongqi Yue's Homepage</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
    <link rel="manifest" href="favicon/site.webmanifest">
    <link rel="mask-icon" href="favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>


<body>
    <div id="container">
        <div id="header">
            <h1><a>Zhongqi <b>Yue</b></a></h1>
            <h2>Dr.</h2>
            <div class="containerbioimage">
            <img src="images/ny_photo.jpg" height="240" style="position:relative;top:10px;right:50px;">
            </div>
            <br><br><br><br><br>
            Presidential Postdoctoral Fellow<br>
            Nanyang Technological University<br>
            <b>Machine generalization</b> from the lens of causality, invariance and beyond<br>
            <!-- Nanyang Technological University, Singapore<br> -->
            <object id="object" data="assets/envelope.svg" width="18" height="18" type="image/svg+xml" style="position:relative;top:4px;"></object>
                    yuez0002[AT]gmail.com<br>
                    <a href="https://scholar.google.com/citations?user=7Iyz9ZYAAAAJ&hl=en" target="_blank"><img src="assets/google_scholar.png" height="26px"></a>
                    <a href="https://github.com/yue-zhongqi" target="_blank"><img src="assets/github.png" height="26px"></a>
                    <a href="https://sg.linkedin.com/in/yue-zhongqi" target="_blank"><img src="assets/linkedin.png" height="26px"></a>
                    <a href="https://dblp.org/pid/275/3790.html" target="_blank"><img src="assets/dblp.png" height="26px"></a>
                    <a href="https://mreallab.github.io/" target="_blank"><img src="assets/location.png" height="26px"></a>
            <div class="clear"></div>
        </div>


        
        <div id="body">
            <div id="Biography">
                <h2>Biography<font size=4></font></h2>
<!--                 <HR style="FILTER: alpha(opacity=60,finishopacity=0,style=3)" width="98%" color=#F0F0F0 SIZE=1> -->
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-bio">
                    <!-- <td class="col-bio">   --> 
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:36px;"> 
                     I am a <a href="https://www.ntu.edu.sg/research/research-careers/presidential-postdoctoral-fellowship-(ppf)">Presidential Postdoctoral Fellow</a> (PPF, Principal Investigator) at Nanyang Technological University (<a href="https://www.ntu.edu.sg/Pages/home.aspx" target="_blank">NTU</a>) in Singapore. In 2023, I completed his Ph.D. in NTU under <a href="https://www.ntu.edu.sg/alibaba-ntu-jri/programmes">Alibaba Talent Program</a>, supervised by <a href="https://personal.ntu.edu.sg/hanwangzhang/">Prof. Hanwang Zhang</a>. During Ph.D., I did an internship in Sea working under<a href="https://panzhous.github.io/"> Dr. Pan Zhou</a>. Prior to that, I received his bachelor's degree from NTU in 2017 under MOE SM2 scholarship.
                     <br>
                     My research is primarily about <b>machine generalization</b>, which aims to train models that perform well on new, unseen data that was not included in their training set. Broadly speaking, I am interested in <b>representation learning</b> that unveils the hidden generative mechanism behind observations in the world; and <b>robust downstream learning</b> that mitigates spurious correlations in the training data, e.g., by causal intervention or invariant learning. I have published papers in top AI/computer vision conferences such as NeurIPS, CVPR and ICCV on a wide range of generalization tasks, including unsupervised learning, zero-/few-shot learning, unsupervised domain adaptation, open-set recognition, etc.
                     <br>
                </table>
            </div>


            <div id="News">
                <h2>News</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1>
                <div class="news" style="overflow:auto; height:200px; Width:99%;padding-top: 6px;">
                <ul>
                <li>[10, 2023]&nbsp;&nbsp;&nbsp; I started a research internship in Sea.</li>
                <li>[09, 2023]&nbsp;&nbsp;&nbsp; 1 paper about unsupervised domain adaptation accepted by <h7>NeurIPS 2023</h7>.</li>
                <li>[08, 2023]&nbsp;&nbsp;&nbsp; Awarded <h7>Wallenberg-NTU Presidential Postdoctoral Fellowship</h7>.</li>
                <li>[07, 2023]&nbsp;&nbsp;&nbsp; 2 papers about open-world detection and fair face recognition are accepted by <h7>ICCV 2023</h7>.</li>
                <li>[03, 2023]&nbsp;&nbsp;&nbsp; 1 paper about video anomaly detection accepted by <h7>CVPR 2023</h7>.</li>
                <li>[08, 2022]&nbsp;&nbsp;&nbsp; Received 2022 <a href="http://www.premiasg.org/">PREMIA</a> Best Student Paper Awards (The Gold Award).</li>
                <li>[09, 2021]&nbsp;&nbsp;&nbsp; 1 paper about self-supervised learning accepted by <h7>NeurIPS 2022</h7> (Spotlight).</li>
                <li>[07, 2021]&nbsp;&nbsp;&nbsp; 1 paper about unsupervised domain adaptation accepted by <h7>ICCV 2021</h7> (Oral).</li>
                <li>[03, 2021]&nbsp;&nbsp;&nbsp; 1 paper about zero-shot learning accepted by <h7>CVPR 2021</h7>.</li>
                <li>[09, 2020]&nbsp;&nbsp;&nbsp; 1 paper about few-shot learning accepted by <h7>NeurIPS 2020</h7>.</li>
                <li>[05, 2020]&nbsp;&nbsp;&nbsp; Joined <h7>Alibaba Talent Program</h7> to do a Ph.D. in NTU.</li>
                </ul>
             </div><br>        
            </div>
            
            <div id="Publications">
                <h2>Publications<font size=4> [<a href="https://scholar.google.com/citations?user=7Iyz9ZYAAAAJ&hl=en" target="_blank">Google Scholar</a>]</font></h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-pub"> 
                     <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2309.12742" target="_blank"><img src="images/ny_icon.PNG"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Make the U in UDA Matter: Invariant Consistency Learning for Unsupervised Domain Adaptation</h6><br>
                                <b>Zhongqi Yue</b>, Hanwang Zhang, Qianru Sun<br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2023.</i><br>
                                <i><d><b>ICON</b></d> <a href="https://wilds.stanford.edu/leaderboard/#with-unlabeled-data" target="_blank">WILDS 2.0 Leaderboard</a> 1st Place (with unlabeled data). <a href="https://github.com/yue-zhongqi/icon" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>
                    
                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.pdf" target="_blank"><img src="images/ny_invreg.PNG"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Invariant Feature Regularization for Fair Face Recognition</h6><br>
                                Jiali Ma, <b>Zhongqi Yue</b>, Tomoyuki Kagaya, Tomoki Suzuki, Karlekar Jayashree, Sugiri Pranata, Hanwang Zhang<br>
                                <i>International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="https://github.com/milliema/InvReg" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2307.08249" target="_blank"><img src="images/randbox.PNG"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Random Boxes Are Open‑world Object Detectors</h6><br>
                                Yanghao Wang, <b>Zhongqi Yue</b>, Xian‑Sheng Hua, Hanwang Zhang<br>
                                <i>International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="https://github.com/scuwyh2000/RandBox" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2303.12369" target="_blank"><img src="images/umil.PNG"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection</h6><br>
                                Hui Lv, <b>Zhongqi Yue</b>, Qianru Sun, Bin Luo, Zhen Cui, Hanwang Zhang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</i><br>
                                <i><a href="https://github.com/ktr-hubrt/UMIL" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2110.15255" target="_blank"><img src="images/ipirm.PNG"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Self-Supervised Learning Disentangled Group Representation as Feature</h6><br>
                                Tan Wang, <b>Zhongqi Yue</b>, Jianqiang Huang, Qianru Sun, Hanwang Zhang<br>
                                <i>Conference on Neural Information Processing Systems (NeurIPS), 2021.</i><br>
                                <i><a href="" target="_blank">Spotlight Presentation 260/9122; 2022 PREMIA Best Student Paper</a>. <a href="https://github.com/Wangt-CN/IP-IRM" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                </table>
            </div>

            <!---->
            <HR color=#F0F0F0 width="97%" SIZE=1>
            <center><font size=2>© Zhongqi Yue | Last updated: 12/12/2023</font></center>
        </div>

        <div class="clear"></div>
    </div>
</body>

</html>
