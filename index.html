
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Zhongqi Yue; Nanyang Technological University; Singapore; Causal Inference; Disentangled Representation; NTU; Transfer Learning; Generalization; ICCV; ECCV; CVPR; Few-shot Learning; Domain Adaptation; Computer Vision; Machine Learning">
    <link rel="author" href="https://yue-zhongqi.github.io/">
    <title>Zhongqi Yue's Homepage</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
    <link rel="manifest" href="favicon/site.webmanifest">
    <link rel="mask-icon" href="favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <!--<meta name="google-site-verification" content="NwoUGJqF5YlommGn9--4pCSkgAvfRBSO7gK2WC_QnEE" />  -->

</head>


<body>
    <div id="container">
        <div id="header">
            <h1><a>Zhongqi <b>Yue</b></a></h1>
            <h2>Dr.</h2>
            <div class="containerbioimage">
            <img src="images/ny_photo.jpg" height="240" style="position:relative;top:10px;right:50px;">
            </div>
            <br><br><br><br><br>
            Presidential Postdoctoral Fellow<br>
            Nanyang Technological University<br>
            <h2>Machine generalization from the lens of causality, invariance and beyond</h2>
            <!-- Nanyang Technological University, Singapore<br> -->
            <object id="object" data="assets/envelope.svg" width="18" height="18" type="image/svg+xml" style="position:relative;top:4px;"></object>
                    yuez0002[AT]gmail.com<br>
            <!--<object id="object" data="assets/envelope.svg" width="18" height="18" type="image/svg+xml" style="position:relative;top:4px;"></object>
                    henghui.ding[AT]ntu.edu.sg<br>-->
            <!-- <p> -->
                    <a href="https://scholar.google.com/citations?user=7Iyz9ZYAAAAJ&hl=en" target="_blank"><img src="assets/google_scholar.png" height="26px"></a>
                    <a href="https://github.com/yue-zhongqi" target="_blank"><img src="assets/github.png" height="26px"></a>
                    <a href="https://sg.linkedin.com/in/yue-zhongqi" target="_blank"><img src="assets/linkedin.png" height="26px"></a>
                    <a href="https://dblp.org/pid/275/3790.html" target="_blank"><img src="assets/dblp.png" height="26px"></a>
                    <!--<a href="https://www.semanticscholar.org/author/Henghui-Ding/49441320" target="_blank"><img src="assets/SemanticScholar.png" height="26px"></a>-->
                    <!--<a href="https://twitter.com/HenghuiDing" target="_blank"><img src="assets/Twitter.png" height="24px"></a>-->
                    <a href="https://mreallab.github.io/" target="_blank"><img src="assets/location.png" height="26px"></a>
            <!-- </p> -->
             <!-- <object id="object" data="assets/envelope.svg" width="18" height="18" type="image/svg+xml" style="position:relative;top:4px;"></object> henghui.ding[AT]ntu.edu.sg -->

            <div class="clear"></div>
        </div>


        
        <div id="body">
            <div id="Biography">
                <h2>Biography<font size=4></font></h2>
<!--                 <HR style="FILTER: alpha(opacity=60,finishopacity=0,style=3)" width="98%" color=#F0F0F0 SIZE=1> -->
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-bio">
                    <!-- <td class="col-bio">   --> 
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:36px;"> 
                     I am a Presidential Postdoctoral Fellow (PPF, Principal Investigator) at Nanyang Technological University (<a href="https://www.ntu.edu.sg/Pages/home.aspx" target="_blank">NTU</a>) in Singapore. In 2023, I completed his Ph.D. in NTU under <a href="https://www.ntu.edu.sg/alibaba-ntu-jri/programmes">Alibaba Talent Program</a>, supervised by <a href="https://personal.ntu.edu.sg/hanwangzhang/">Prof. Hanwang Zhang</a>. During Ph.D., I did an internship in Sea working under<a href="https://panzhous.github.io/"> Dr. Pan Zhou</a>. Prior to that, I received his bachelor's degree from NTU in 2017 under MOE SM2 scholarship.
                     <br>
                     My research is primarily about <b>machine generalization</b>, which aims to train models that perform well on new, unseen data that was not included in their training set. Broadly speaking, I am interested in <b>representation learning</b> that unveils the hidden generative mechanism behind observations in the world; and <b>robust downstream learning</b> that mitigates spurious correlations in the training data, e.g., by causal intervention or invariant learning. I have published papers in top AI/computer vision conferences such as NeurIPS, CVPR and ICCV on a wide range of generalization tasks, including unsupervised learning, zero-/few-shot learning, unsupervised domain adaptation, open-set recognition, etc.
                     <br>
                     <!-- <font color="red">If you are interested in joining/visitng or remotely collaborating with our group, please do not hesitate to drop me an email with your resume. Looking for visiting Ph.D. students under the support of <a href="https://www.csc.edu.cn/chuguo" target="_blank">CSC</a> or other fundings.</font><br> -->
                     <!-- We will usually reply within a week if we have a suitable position. -->
<!--                     <object id="object" data="assets/envelope.svg" width="18" height="18" type="image/svg+xml" style="position:relative;top:4px;"></object> &nbsp;
                    henghui.ding[AT]gmail.com &nbsp;&nbsp; henghui.ding[AT]ntu.edu.sg<br> -->
                    </p>
                    <!-- </td> -->
<!--                    <td class="col-bioimage">
                        <img src="images/henghuiding.jpg" style="position:relative;bottom:13px;">
                    </td> -->
                </table>
            </div>


            <div id="News">
                <h2>News</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1>
                <div class="news" style="overflow:auto; height:200px; Width:99%;padding-top: 6px;">
                <ul>
                <li>[11, 2023]&nbsp;&nbsp;&nbsp; 1 paper accepted to <h7>IEEE TIP</h7>.</li>
                <li>[10, 2023]&nbsp;&nbsp;&nbsp; 1 paper accepted to <h7>IEEE TPAMI</h7>.</li>
                <li>[09, 2023]&nbsp;&nbsp;&nbsp; Several papers accepted, 1 <h7>NeurIPS</h7>, 1 <h7>IEEE TIFS</h7>, 1 <h7>PR</h7>.</li>
                <li>[08, 2023]&nbsp;&nbsp;&nbsp; Serving as an <h7>Area Chair for CVPR 2024</h7>.</li>
                <li>[08, 2023]&nbsp;&nbsp;&nbsp; <a href="https://henghuiding.github.io/MeViS" target="_blank">MeViS Dataset</a> is released. <a href="https://codalab.lisn.upsaclay.fr/competitions/15094" target="_blank">Evaluation server</a> is online.</li>
                <!-- <small>&#11088;</small>  <small>&#127881;</small> <small>&#128293;</small> -->
                <li>[07, 2023]&nbsp;&nbsp;&nbsp; Serving as a Senior Program Committee (SPC) member for <h7>AAAI 2024</h7>.</li>
                <li>[07, 2023]&nbsp;&nbsp;&nbsp; 5 papers accepted to <h7>ICCV 2023</h7>.</li>
                <li>[07, 2023]&nbsp;&nbsp;&nbsp; <a href="https://henghuiding.github.io/MOSE" target="_blank"><d><b>MOSE Dataset</b></d></a> accepted to ICCV 2023.</li>
                <li>[05, 2023]&nbsp;&nbsp;&nbsp; Named <h7>CVPR 2023 Outstanding Reviewer</h7>.</li>
                <li>[05, 2023]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>IEEE TIP</h7>.</li>
                <li>[03, 2023]&nbsp;&nbsp;&nbsp; 6 papers accepted to <h7>CVPR 2023</h7>, 1 Highlight.</li>
                <li>[02, 2023]&nbsp;&nbsp;&nbsp; <a href="https://henghuiding.github.io/MOSE" target="_blank">MOSE Dataset</a> is released. <a href="https://codalab.lisn.upsaclay.fr/competitions/10703" target="_blank">Evaluation server</a> is online.</li>
                <li>[12, 2022]&nbsp;&nbsp;&nbsp; Serving as a Senior Program Committee (SPC) member for <h7>IJCAI 2023</h7>.</li>
                <li>[11, 2022]&nbsp;&nbsp;&nbsp; Serving as an Associate Editor for <h7>IET Computer Vision</h7>.</li>
                <li>[10, 2022]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>IEEE TPAMI</h7>.</li>
                <li>[09, 2022]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>NeurIPS 2022</h7>.</li>
                <li>[07, 2022]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>ECCV 2022</h7>.</li>
                <li>[03, 2022]&nbsp;&nbsp;&nbsp; 4 papers accepted to <h7>CVPR 2022</h7>.</li>
                <li>[09, 2021]&nbsp;&nbsp;&nbsp; 2 papers accepted to <h7>NeurIPS 2021</h7>.</li>
                <li>[09, 2021]&nbsp;&nbsp;&nbsp; Serving as a Senior Program Committee (SPC) member for <h7>AAAI 2022</h7>.</li>
                <li>[07, 2021]&nbsp;&nbsp;&nbsp; 8 papers accepted to <h7>ICCV 2021</h7>.</li>   
                </ul>
             </div><br>        
            </div>



            <div id="Publications">
                <h2>Selected Publications<font size=4> [<a href="https://scholar.google.com/citations?user=WI_flSwAAAAJ&hl=en" target="_blank">Google Scholar</a>]</font></h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <table class="table-pub"> 


                     <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/MeViS" target="_blank"><img src="images/ICCV23_MeViS.webp"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions</h6><br>
                                <b>Henghui Ding</b>, Chang Liu, Shuting He, Xudong Jiang, Chen Change Loy<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="" target="_blank"><d><b>MeViS</b></d></a> A benchmark dataset of Video Segmentation with Motion Expressions. <a href="https://henghuiding.github.io/MeViS" target="_blank">&#128293;Project Page&#128293;</a> </i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/MOSE" target="_blank"><img src="images/0442a954.webp"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>MOSE: A New Dataset for Video Object Segmentation in Complex Scenes</h6><br>
                                <b>Henghui Ding</b>, Chang Liu, Shuting He, Xudong Jiang, Philip H.S. Torr, Song Bai<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2023.</i><br>
                                <i><a href="https://henghuiding.github.io/MOSE" target="_blank"><d><b>MOSE</b></d></a> A benchmark dataset of co<b><d>M</b></d>plex video <b><d>O</d></b>bject <b><d>SE</d></b>gmentation <a href="https://henghuiding.github.io/MOSE" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                     <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/9932025" target="_blank"><img src="images/VLT_TPAMI.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>VLT: Vision-Language Transformer and Query Generation for Referring Segmentation</h6><br>
                                <b>Henghui Ding</b>, Chang Liu, Suchen Wang, Xudong Jiang<br>
                                <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023.</i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/GRES" target="_blank"><img src="images/CVPP23_GRES.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>GRES: Generalized Referring Expression Segmentation</h6><br>
                                Chang Liu<sup>&#42;</sup>, <b>Henghui Ding</b><sup>&#42; <object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Xudong Jiang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship, &#42; Equal contribution)<br>
                                <i>A new task and benchmark dataset of referring image segmentation: <a href="https://henghuiding.github.io/GRES" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                                <d>Hightlight, Acceptance Rate 2.5%.</d></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/PADing" target="_blank"><img src="images/CVPR23_PADing.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Primitive Generation and Semantic-related Alignment for Universal Zero-Shot Segmentation</h6><br>
                                Shuting He<sup>&#42;</sup>, <b>Henghui Ding</b><sup>&#42; <object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Wei Jiang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship, &#42; Equal contribution)<br>
                                <i>The first unfied zero-shot segmentation framework: <a href="https://henghuiding.github.io/PADing" target="_blank">&#128293;Project Page&#128293;</a></i><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://henghuiding.github.io/D2Zero/" target="_blank"><img src="images/CVPR23_D2Zero.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation</h6><br>
                                Shuting He<sup>&#42;</sup>, <b>Henghui Ding</b><sup>&#42; <object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Wei Jiang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship, &#42; Equal contribution)<br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/10138737/" target="_blank"><img src="images/TIP_FZshot3D.jpg"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Prototype Adaption and Projection for Few- and Zero-shot 3D Point Cloud Semantic Segmentation</h6><br>
                                Shuting He, Xudong Jiang, Wei Jiang, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup><br>
                                <i>IEEE Transactions on Image Processing (TIP), 2023.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br><br>
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/10132374" target="_blank"><img src="images/TIP_M3Att.jpg"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Multi-Modal Mutual Attention and Iterative Interaction for Referring Image Segmentation</h6><br>
                                Chang Liu, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Yulun Zhang, Xudong Jiang<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2023.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br><br>
                            </div>
                        </td>
                    </tr>


                     <tr>
                        <td class="col-pubimage"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322004988" target="_blank"><img src="images/SRPNet.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Self-Regularized Prototypical Network for Few-Shot Semantic Segmentation</h6><br>
                                <b>Henghui Ding</b>, Hui Zhang, Xudong Jiang<br>
                                <i>Pattern Recognition (PR), 2023.</i><br><br>
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/abstract/document/9745353" target="_blank"><img src="images/TMM22.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Instance-Specific Feature Propagation for Referring Segmentation</h6><br>
                                Chang Liu, Xudong Jiang, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> </sup><br>
                                <i>IEEE Transactions on Multimedia (TMM), 2022.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322003168" target="_blank"><img src="images/6DPR.jpg"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Spatial Feature Mapping for 6DoF Object Pose Estimation</h6><br>
                                Jianhan Mei, Xudong Jiang, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup><br>
                                <i>Pattern Recognition (PR), 2022.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/9807336" target="_blank"><img src="images/TCSVT22.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Distilling Knowledge from Object Classification to Aesthetics Assessment</h6><br>
                                Jingwen Hou&#42;, <b>Henghui Ding</b>&#42;, Weisi Lin, Weide Liu, Yuming Fang<br>
                                <i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2022.<br>
                                (&#42; Equal contribution)<br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/2205.12627" target="_blank"><img src="images/CVPR22_Primitive3D.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Primitive3D: 3D Object Dataset Synthesis from Randomly Assembled Primitives</h6><br>
                                Xinke Li&#42;, <b>Henghui Ding</b>&#42;, Zekun Tong, Yuwei Wu, Yeow Meng Chee<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.<br>
                                (&#42; Equal contribution)<br><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://github.com/GuoleiSun/VSS-CFFM" target="_blank"><img src="images/CVPR22_VSS.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Coarse-to-Fine Feature Mining for Video Semantic Segmentation</h6><br>
                                Guolei Sun, Yun Liu, <b>Henghui Ding</b>, Thomas Probst, Luc Van Gool<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.<br>
                                <br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/abstract/document/9730784" target="_blank"><img src="images/TIP22.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Deep Interactive Image Matting with Feature Propagation</h6><br>
                                <b>Henghui Ding</b>, Hui Zhang, Chang Liu, Xudong Jiang<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2022.<br>
                                <br>
                            </div>
                        </td>
                    </tr>

                     <tr>
                        <td class="col-pubimage"><a href="https://github.com/flyingtango/DiGCL" target="_blank"><img src="images/NeurIPS21_DiGGL.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Directed Graph Contrastive Learning</h6><br>
                                Zekun Tong, Yuxuan Liang, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Yongxing Dai, Xinke Li, Changhu Wang<br>
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br>
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-pubimage"><a href="https://github.com/henghuiding/Vision-Language-Transformer" target="_blank"><img src="images/ICCV21_VLT.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Vision-Language Transformer and Query Generation for Referring Segmentation</h6><br>
                                <b>Henghui Ding</b>, Chang Liu, Suchen Wang, Xudong Jiang<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.<br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ding_Interaction_via_Bi-Directional_Graph_of_Semantic_Region_Affinity_for_Scene_ICCV_2021_paper.pdf" target="_blank"><img src="images/ICCV21_Parsing.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Interaction via Bi-directional Graph of Semantic Region Affinity for Scene Parsing</h6><br>
                                <b>Henghui Ding</b>, Hui Zhang, Jun Liu, Jiaxin Li, Zijian Feng, Xudong Jiang<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.<br><br>
                            </div>
                        </td>
                    </tr>

                   <!--  <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Meta_Navigator_Search_for_a_Good_Adaptation_Policy_for_Few-Shot_ICCV_2021_paper.pdf" target="_blank"><img src="images/ICCV21_Meta.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Meta Navigator: Search for a Good Adaptation Policy for Few-shot Learning</h6><br>
                                Chi Zhang<sup>#</sup>, <b>Henghui Ding</b>, Guosheng Lin, Ruibo Li, Changhu Wang, Chunhua Shen<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.<br>
                                (# Henghui's Intern at ByteDance AI Lab)<br><br>
                            </div>
                        </td>
                    </tr> -->

                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Prototypical_Matching_and_Open_Set_Rejection_for_Zero-Shot_Semantic_Segmentation_ICCV_2021_paper.pdf" target="_blank"><img src="images/ICCV21_Zero.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Prototypical Matching and Open Set Rejection for Zero-Shot Semantic Segmentation</h6><br>
                                Hui Zhang, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup><br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2021.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br><br>
                            </div>
                        </td>
                    </tr>

<!--                     <tr>
                        <td class="col-pubimage"><a href="https://github.com/coldmanck/recovering-unbiased-scene-graphs" target="_blank"><img src="images/ACMMM2021.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Recovering the Unbiased Scene Graphs from the Biased Ones</h6><br>
                                Meng-Jiun Chiou<sup>#</sup>, <b>Henghui Ding</b>, Hanshu Yan, Changhu Wang, Roger Zimmermann, Jiashi Feng<br>
                                <i>ACM International Conference on Multimedia, 2021.<br>
                                (# Henghui's Intern at ByteDance AI Lab)<br><br>
                            </div>
                        </td>
                    </tr> -->

                    <tr>
                        <td class="col-pubimage"><a href="https://openaccess.thecvf.com/content/WACV2021/papers/Liu_Towards_Enhancing_Fine-Grained_Details_for_Image_Matting_WACV_2021_paper.pdf" target="_blank"><img src="images/wacv21.jpg"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Towards Enhancing Fine-grained Details for Image Matting</h6><br>
                                Chang Liu, <b>Henghui Ding</b><sup><object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object></sup>, Xudong Jiang<br>
                                <i>IEEE Winter Conference on Applications of Computer Vision (WACV), 2021.<br>
                                (<object id="object" data="assets/envelope.svg" width="12" height="12" type="image/svg+xml"></object> Corresponding Authorship)<br>
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-pubimage"><a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480426.pdf" target="_blank"><img src="images/ECCV20.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>PhraseClick: Toward Achieving Flexible Interactive Segmentation by Phrase and Click</h6><br>
                                <b>Henghui Ding</b>, Scott Cohen, Brian Price, Xudong Jiang<br>
                                <i>European Conference on Computer Vision (ECCV), 2020.<br>
                                <d>Spotlight presentation, Acceptance Rate 5.3%.</d></i><br>
                                <i>Work done when intern at Adobe Research<br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/8954873" target="_blank"><img src="images/TIP20.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Semantic Segmentation with Context Encoding and Multi-Path Decoding</h6><br>
                                <b>Henghui Ding</b>, Xudong Jiang, Bing Shuai, Ai Qun Liu, Gang Wang<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2020.</i><br>
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-pubimage"><a href="https://arxiv.org/abs/1901.04877" target="_blank"><img src="images/TPAMI19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Feature Boosting Network For 3D Pose Estimation</h6><br>
                                Jun Liu, <b>Henghui Ding</b>, Amir Shahroudy, Ling-Yu Duan, Xudong Jiang, Gang Wang, Alex C. Kot<br>
                                <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020.</i><br><br>
                            </div>
                        </td>
                    </tr>

                    
                    
                    <tr>
                        <td class="col-pubimage"><a href="https://github.com/henghuiding/EFCN" target="_blank"><img src="images/TIP19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Toward Achieving Robust High-level and Low-level Scene Parsing</h6><br>
                                <b>Henghui Ding</b>&#42;, Bing Shuai&#42;, Ting Liu, Gang Wang, Xudong Jiang<br>
                                <i>IEEE Transactions on Image Processing (TIP), 2019.</i><br>
                                (&#42; Equal contribution)<br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="https://github.com/henghuiding/BFP" target="_blank"><img src="images/ICCV19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Boundary-Aware Feature Propagation for Scene Segmentation</h6><br>
                                <b>Henghui Ding</b>, Xudong Jiang, Ai Qun Liu, Nadia Magnenat Thalmann, Gang Wang<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019.</i><br><br>
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-pubimage"><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Ding_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation_CVPR_2019_paper.pdf" target="_blank"><img src="images/CVPR19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Semantic Correlation Promoted Shape-Variant Context for Segmentation</h6><br>
                                <b>Henghui Ding</b>, Xudong Jiang, Bing Shuai, Ai Qun Liu, Gang Wang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.<br>
                                    <d href="https://youtu.be/Vte9QaXEP_w?list=PLir6j8POxtqVePcKnDpq5ZJkGkBu96WP3&t=2501" target="_blank">Oral presentation, Acceptance Rate 5.6%.</d></i><br>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="col-pubimage"><a href="https://github.com/henghuiding/CCL" target="_blank"><img src="images/CVPR18.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Context Contrasted Feature and Gated Multi-Scale Aggregation for Scene Segmentation</h6><br>
                                <b>Henghui Ding</b>, Xudong Jiang, Bing Shuai, Ai Qun Liu, Gang Wang<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.<br>
                                <d href="https://youtu.be/giA2rpN3Iv8?list=PL_bDvITUYucCIT8iNGW8zCXeY5_u6hg-y&t=411" target="_blank">Oral presentation, Acceptance Rate 2.1%.</d></i><br><br>
                            </div>
                        </td>
                    </tr>

                    
                    
                    <!-- <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/8917805" target="_blank"><img src="images/TIPwxh20.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Bi-directional Dermoscopic Feature Learning and Multi-scale Consistent Decision Fusion for Skin Lesion Segmentation</h6><br>
                                Xiaohong Wang, Xudong Jiang, <b>Henghui Ding</b>, and Jun Liu<br>
                                <i>Accepted by IEEE Transactions on Image Processing (TIP).</i><br><br>
                            </div>
                        </td>
                    </tr> -->
            
                    <!-- <tr>
                        <td class="col-pubimage"><a href="https://link.springer.com/article/10.1007/s11042-019-7251-y" target="_blank"><img src="images/MTAP19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>DeepDeblur: Text Image Recovery From Blur to Sharp</h6><br>
                                Jianhan Mei, Ziming Wu, Xiang Chen, Yu Qiao, <b>Henghui Ding</b>, and Xudong Jiang<br>
                                <i>Multimedia Tools and Applications (MTAP), 2019.</i><br><br>
                            </div>
                        </td>
                    </tr> -->
                    
                    <!-- <tr>
                        <td class="col-pubimage"><a href="https://ieeexplore.ieee.org/document/8802999" target="_blank"><img src="images/ICIP19.png"></a></td>
                        <td>
                            <div class="pub-info" style="padding-right:20px;">
                                <h6>Dermoscopic Image Segmentation through the Enhanced High-level Parsing and Class Weighted Loss</h6><br>
                                Xiaohong Wang, <b>Henghui Ding</b>, and Xudong Jiang<br>
                                <i>IEEE International Conference on Image Processing (ICIP), 2019.</i><br><br>
                            </div>
                        </td>
                    </tr> -->

                </table>
            </div>
            <div id="Activities">
                <h2>Activities</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <ul>
                    <li>Associate Editor, IET Computer Vision, 2022-Present.</li>
                    <li>Area Chair, CVPR'24.</li>
                    <li>Senior Program Committee (SPC): AAAI'(22-24), IJCAI'23.</li>
                    <li>Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, AAAI, WACV, BMVC, ICRA, ICIP, etc.</li>
                    <li>Journal Reviewer: TPAMI, IJCV, TIP, TMI, TNNLS, TMM, TCSVT, PR, Neurocomputing, SPL, etc.</li>
                    <li>Internship: Adobe Research, San José, USA.</li>

                </ul>
            </div>
            <div id="Patents">
                <h2>Patents</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <ul>
                    <li>US Patent App. 16/839,209, 2021, Integrated Interactive Image Segmentation.</li>

                </ul>
            </div>
            <div id="teaching">
                <h2>Teaching</h2>
                <HR color=#F0F0F0 width="97%" SIZE=1><br>
                <ul>
                    <li>
                        Semester 2, 2018-2019, &nbsp;&nbsp; E2010L/IM2004: Signals&Systems, NTU
                    </li>
                    <li>
                        Semester 2, 2018-2019, &nbsp;&nbsp; E2004: Digital Electronics, NTU
                    </li>
                    <li>
<!--                         <div style="float:left;">E2010L/IM2004: Signals & Systems, NTU</div>
                        <div style="float:right;padding-right:20px;">Semester 2, 2018-2019</div> -->
                        Semester 1, 2018-2019, &nbsp;&nbsp; EE4717: Web Application Design, NTU
                    </li>

                </ul>
            </div>
            <HR color=#F0F0F0 width="97%" SIZE=1>
            <center><font size=2>© Henghui Ding | Last updated: 23/11/2023</font></center>
        </div>
        <div class="clear"></div>
    </div>


<a href="https://clustrmaps.com/site/1b1v3" title="Visit tracker" target="_blank"><img src="//www.clustrmaps.com/map_v2.png?d=JArK5aIJ4_JNpTFXJAWrh9qrhIjHKqtRpSEtKEbO-eY&cl=ffffff"height="2"/ style="display:block;margin-top:5px;margin-bottom:0px;margin-left:auto;text-align:right"></a>
</body>

</html>
